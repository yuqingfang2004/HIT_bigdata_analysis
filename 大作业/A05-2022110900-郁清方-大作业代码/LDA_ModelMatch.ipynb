{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81e96803",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\14850\\AppData\\Local\\Temp\\ipykernel_11268\\1184561296.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已将日志模板的独热码主题保存到CSV文件：E:\\Code for Project2024\\Data_for_Train\\L1\\log_templates_one_hot.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import LdaModel\n",
    "from gensim import corpora\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# 假定已经有一个预处理函数\n",
    "def nltk_preprocess(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = word_tokenize(text.lower())\n",
    "    return [word for word in words if word.isalpha() and word not in stop_words]\n",
    "\n",
    "# 加载之前训练的LDA模型和词典\n",
    "lda_model = LdaModel.load(r'E:\\Code for Project2024\\lda_model\\model')\n",
    "dictionary = corpora.Dictionary.load(r'E:\\Code for Project2024\\lda_model\\dictionary')\n",
    "\n",
    "# 读取新的日志模板文件\n",
    "structured_log_df = pd.read_csv(r'E:\\Code for Project2024\\Data_for_Train\\L1\\HDFS.log_for_L1.csv')\n",
    "\n",
    "# 预处理日志数据\n",
    "structured_log_df['Preprocessed'] = structured_log_df['EventTemplate'].apply(nltk_preprocess)\n",
    "\n",
    "# 转换为词袋模型\n",
    "structured_corpus = [dictionary.doc2bow(text) for text in structured_log_df['Preprocessed']]\n",
    "\n",
    "# 使用LDA模型进行主题预测\n",
    "structured_log_df['TopicDistribution'] = [lda_model.get_document_topics(bow) for bow in structured_corpus]\n",
    "\n",
    "# 将概率分布向量转换为易于阅读的格式\n",
    "def format_distribution(distribution):\n",
    "    return {f\"Topic {topic}\": f\"{prob:.2%}\" for topic, prob in distribution}\n",
    "\n",
    "# 将主题分布转换为易于阅读的字符串形式\n",
    "structured_log_df['FormattedDistribution'] = structured_log_df['TopicDistribution'].apply(format_distribution)\n",
    "\n",
    "\n",
    "# 展示预测结果的前几行\n",
    "pd.set_option('display.max_colwidth', None) \n",
    "structured_log_df[['EventTemplate', 'FormattedDistribution']].head\n",
    "\n",
    "# 将主题分布转换为最可能主题的独热码\n",
    "def get_one_hot(topic_dist, num_topics):\n",
    "    one_hot = np.zeros(num_topics, dtype=int)\n",
    "    most_probable_topic_index = max(topic_dist, key=lambda x: x[1])[0]\n",
    "    one_hot[most_probable_topic_index] = 1\n",
    "    return one_hot\n",
    "\n",
    "# 获取LDA模型的主题数量\n",
    "num_topics = lda_model.num_topics\n",
    "\n",
    "# 计算每个日志模板最可能的主题的独热码\n",
    "structured_log_df['OneHotTopic'] = structured_log_df['TopicDistribution'].apply(lambda x: get_one_hot(x, num_topics))\n",
    "\n",
    "# 保存到CSV文件\n",
    "output_csv_path = r'E:\\Code for Project2024\\Data_for_Train\\L1\\log_templates_one_hot.csv'\n",
    "structured_log_df.to_csv(output_csv_path, columns=['EventTemplate', 'OneHotTopic'], index=False)\n",
    "\n",
    "print(f\"已将日志模板的独热码主题保存到CSV文件：{output_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab32eed6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
